# -*- coding: utf-8 -*-
"""Loan Analyst.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xKsHX6SjnzmI2ek4N6K17A__rIhWnh9n

# **Loan Approvals**

*   `Gender` : Gender of Person
*   `Married` : Marital Status
*   `Dependents` : Number of dependents
*   `Education` : Education Level
*   `Self_Employed` : If they are self employed.
*   `Applicant_Income` : Income of applicant
*   `Coapplicant_Income` : Income of co applicant.
*   `Loan_Amount` : Loan Amount
*   `Term` : Term of loan
*   `Credit_History` : If they have good/bad credit history.
*   `Area` : Geographical Area
*   `Status` : Loan approval status

[Loan Approvals Dataset](https://www.kaggle.com/datasets/prateekmaj21/loan-approvals)

Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('loan_data.csv')

df.head(10)

"""## **Exploratory Data Analysis**"""

df.info()

df.describe()

!pip install summarytools
from summarytools import dfSummary
dfSummary(df)

"""### **Data Cleansing**"""

# Checking missing value
df.isnull().sum()

"""**fill the nan value in the `Gender` column with the mode value**"""

df.Gender.value_counts()

#Tracking missing value in Gender
df[df['Gender'].isna()==1]

mode_gender = df['Gender'].mode()[0]
df['Gender'].fillna(mode_gender,inplace=True)

df['Gender'].value_counts()

"""**fill the nan value in the `Self_Employee` column with the mode value**"""

df.Self_Employed.value_counts()

df[df['Self_Employed'].isna()==1]

Self_employed_value = df['Self_Employed'].mode()[0]
df['Self_Employed'].fillna(Self_employed_value, inplace=True)

df['Self_Employed'].value_counts()

"""**fill the nan value in the `Dependents` column with the mode value and change `3+` to `3` and astype to Int**"""

df['Dependents'].value_counts()

df[df['Dependents'].isna()==1]

mode_dependents = df['Dependents'].mode()[0]
df['Dependents'].fillna(mode_dependents, inplace=True)

df['Dependents'] = df['Dependents'].replace('3+', 3)
df['Dependents'] = df['Dependents'].astype(int)

df['Dependents'].value_counts()

"""fill the nan value in the Credit_history_mode column with the mode value"""

credit_history_mode = df['Credit_History'].mode()[0]
df['Credit_History'].fillna(credit_history_mode, inplace=True)

df['Credit_History'].value_counts()

df['Credit_History'] = df['Credit_History'].replace(1.0, 'Yes')
df['Credit_History'] = df['Credit_History'].replace(0.0, 'No')
df['Credit_History'].value_counts()

"""fill the nan value in the `Married` column with the mode value"""

df[df['Married'].isna()==1]

df['Married'].fillna(df['Married'].mode()[0], inplace=True)

df.isna().sum()

"""fill the nan value in the `Term` column with the mode value"""

df['Term'].value_counts()

df[df['Term'].isna()==1]

df['Term'].fillna(df['Term'].median(), inplace=True)

df['Term'].value_counts()

#Handling missing data completed
df.isna().sum()

categorical_data = df.select_dtypes(include=['object'])
categorical_data

plt.figure(figsize=(15,10))
num_cols = len(categorical_data.columns)
for i, col in enumerate(categorical_data.columns):
    plt.subplot(1, num_cols, i + 1)
    sns.countplot(x=df[col], color='blue')
    plt.title(col)
    plt.tight_layout()

numerical_data = df.select_dtypes(include=['int64', 'float64'])
numerical_data.head()

#bins of data
df.hist(figsize=(5,10))
plt.show()

#numerical data
plt.figure(figsize=(20,10))
correlation_matrix = numerical_data.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')

sns.pairplot(data=df, hue='Status')

sns.pairplot(data=df, hue='Gender')

"""Bivariate Analysis"""

df.groupby('Status')['Applicant_Income'].describe().T

df.groupby('Gender')[['Applicant_Income']].describe().T

df.groupby('Married')[['Applicant_Income','Loan_Amount']].describe().T

df.groupby(['Status','Gender'])['Loan_Amount'].mean()

"""### Preprocessing Data"""

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

categorical_data.head()

label_encoder = LabelEncoder()
for column in categorical_data.columns:
    df[column] = label_encoder.fit_transform(df[column])

scaler = StandardScaler
df[numerical_data.columns] = scaler().fit_transform(df[numerical_data.columns])

df.head()

x = df.drop('Status', axis=1)
y = df['Status']

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=11)

"""### Build Model
create model from 3 model algorithm and find the best model for this case.
"""

!pip install xgboost
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from xgboost import XGBClassifier

def models(x_train,y_train):

  loreg=LogisticRegression()
  loreg.fit(x_train,y_train)

  Xgb=XGBClassifier()
  Xgb.fit(x_train,y_train)

  svc=SVC()
  svc.fit(x_train,y_train)

  print('[0] Logistic Regression Training Accuracy:', loreg.score(x_train, y_train))
  print('[1] XGBoost Classifier Training Accuracy:', Xgb.score(x_train, y_train))
  print('[2] Support Vector Machine Training Accuracy:', svc.score(x_train, y_train))

  return loreg, Xgb, svc

"""Showing score from trained model"""

model = models(x_train,y_train)

"""testing and showing the conf metrics"""

for i in range(len(model)):
  cm = confusion_matrix(y_test, model[i].predict(x_test))
  TN, FP, FN, TP = confusion_matrix(y_test, model[i].predict(x_test)).ravel()
  print(cm)
  print('Model[{}] Testing Accuracy = "{} "'.format(i,  (TP + TN) / (TP + TN + FN + FP)))
  print()

"""from the testing accuracy we can conclude that XGBoost is the best model among the other 2 models"""

xgboost = XGBClassifier()
fix_model = xgboost.fit(x_train, y_train)
fix_model.score(x_train, y_train)

pred = fix_model.predict(x_test)
cf_matrix = confusion_matrix(y_test, pred)
#fmt='.2%'
# Visualize Confution Matrix
sns.heatmap(cf_matrix/np.sum(cf_matrix),fmt='.2%', annot=True)
plt.title('Confusion Matrix of XGBoostClassifier', fontsize=12)
plt.xlabel('Predicted', fontsize=12)
plt.ylabel('Actual', fontsize=12)
plt.show()

"""Saving model to pickle"""

import pickle
with open('XGBoost_model.pkl', 'wb') as file:
    pickle.dump(fix_model, file)